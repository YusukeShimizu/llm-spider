---
title: CLI
description: Run llm-spider as a CLI.
---

`llm-spider` prints Markdown to stdout.
Logs go to stderr.

## Environment

- `OPENAI_API_KEY` is required.
- Optional: `OPENAI_BASE_URL`, `LLM_SPIDER_OPENAI_*`.

| Variable | Default | Description |
|----------|---------|-------------|
| `OPENAI_API_KEY` | (required) | OpenAI API key |
| `OPENAI_BASE_URL` | `https://api.openai.com/v1/` | API base URL |
| `LLM_SPIDER_OPENAI_SEARCH_MODEL` | `gpt-5.2` | Model for web search |
| `LLM_SPIDER_OPENAI_SELECT_MODEL` | `gpt-5.2` | Model for child link selection |
| `LLM_SPIDER_OPENAI_REASONING_EFFORT` | `medium` | Reasoning effort (`none`, `minimal`, `low`, `medium`, `high`, `xhigh`) |

## Run

```sh
cargo run -- spider --query "example query"
```

## Content extraction

Each fetched page is processed with `readability-rust` to extract the main
article content, then converted to Markdown via `htmd`.
If extraction fails, the output falls back to a plain-text excerpt.

## Budgets

The crawl is constrained by budgets.

- `--max-pages`: Maximum pages to fetch.
- `--max-depth`: Maximum link depth.
- `--max-elapsed`: Maximum elapsed time (for example, `30s`).
- `--max-chars`: Maximum output size (page-boundary granularity).

`--max-chars` stops including pages once the next page would push the total
output beyond the limit. At least one page is always included.
Pages are never truncated mid-content.

Example:

```sh
cargo run -- spider \
  --query "example query" \
  --max-pages 10 \
  --max-depth 1 \
  --max-elapsed 20s \
  --max-chars 4000
```

## Help

```sh
cargo run -- spider --help
```
